{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Confirm we have enough memory**"
      ],
      "metadata": {
        "id": "hdKRxfsguxjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYncvH4YmqMJ",
        "outputId": "4e5add38-c675-4f6f-b170-b3bfc06157d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:              12           1           0           0          10          10\n",
            "Swap:              0           0           0\n"
          ]
        }
      ],
      "source": [
        "!free -g"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install kaggle and autogluon**"
      ],
      "metadata": {
        "id": "3dD4MjN4njSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezjpbj20mesz",
        "outputId": "e58d9628-83ca-4888-9e83-c11d4c7bf973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: uv in /usr/local/lib/python3.10/dist-packages (0.4.10)\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 89ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 193ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 110ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 145ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.3.1\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install uv\n",
        "!uv pip install kaggle --system\n",
        "!uv pip install autogluon --system\n",
        "!uv pip install torch==2.3.1 --system\n",
        "!uv pip uninstall torchaudio --system"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google drive and copy kaggle.json to local disk**"
      ],
      "metadata": {
        "id": "a33qZ-VsnqaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('mount')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pDWJil5nh5e",
        "outputId": "dd1ddac9-8c56-4e49-e701-c2b84851b6ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at mount; to attempt to forcibly remount, call drive.mount(\"mount\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp mount/MyDrive/kaggle.json ."
      ],
      "metadata": {
        "id": "A3bOI0-dn_5C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download kaggle dataset for fraud detection**"
      ],
      "metadata": {
        "id": "dQGIqBoqoB18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!KAGGLE_CONFIG_DIR=$(pwd) kaggle competitions download -c california-house-prices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNFYuv2roMaW",
        "outputId": "d22bfb36-968c-4332-8f30-7fdcdf7d2fee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "california-house-prices.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract dataset files**"
      ],
      "metadata": {
        "id": "S66tiqWsqFkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "![[ -d california-house-prices ]] && rm -rf california-house-prices\n",
        "!ls\n",
        "!unzip california-house-prices.zip -d california-house-prices\n",
        "!ls\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu0_3lndpw36",
        "outputId": "c6187e3a-542c-4930-d9ef-23cedd30ac80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "california-house-prices.zip  kaggle_house.py  kaggle.json  logs  mount\tsample_data\n",
            "Archive:  california-house-prices.zip\n",
            "  inflating: california-house-prices/sample_submission.csv  \n",
            "  inflating: california-house-prices/test.csv  \n",
            "  inflating: california-house-prices/train.csv  \n",
            "california-house-prices      kaggle_house.py  logs   sample_data\n",
            "california-house-prices.zip  kaggle.json      mount\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Model Trainer Example python file from Github**"
      ],
      "metadata": {
        "id": "w-B5WxjA9K-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://raw.githubusercontent.com/autogluon/autogluon/master/examples/automm/kaggle_california_house_price/example_kaggle_house.py"
      ],
      "metadata": {
        "id": "L9fdZ9rM9VgN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the experiments**"
      ],
      "metadata": {
        "id": "xM5PqQlc9ZUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p logs"
      ],
      "metadata": {
        "id": "arUHZzTlALGm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kaggle_house.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from autogluon.multimodal import MultiModalPredictor\n",
        "import torch as th\n",
        "\n",
        "\n",
        "def get_parser():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='The Basic Example of AutoGluon for House Price Prediction.')\n",
        "    parser.add_argument('--mode',\n",
        "                        choices=['stack5',\n",
        "                                 'weighted',\n",
        "                                 'single',\n",
        "                                 'single_bag5'],\n",
        "                        default='weighted',\n",
        "                        help='\"stack5\" means 5-fold stacking. \"weighted\" means weighted ensemble.'\n",
        "                             ' \"single\" means use a single model.'\n",
        "                             ' \"single_bag5\" means 5-fold bagging via the AutoMM model.')\n",
        "    parser.add_argument('--automm-mode', choices=['ft-transformer', 'mlp'],\n",
        "                        default='ft-transformer', help='Fusion model in AutoMM.')\n",
        "    parser.add_argument('--text-backbone', default='google/electra-small-discriminator')\n",
        "    parser.add_argument('--cat-as-text', default=False)\n",
        "    parser.add_argument('--data_path', type=str, default='california-house-prices')\n",
        "    parser.add_argument('--seed', type=int, default=123)\n",
        "    parser.add_argument('--exp_path', default=None)\n",
        "    parser.add_argument('--with_tax_values', default=1, type=int)\n",
        "    return parser\n",
        "\n",
        "\n",
        "def get_automm_hyperparameters(mode, text_backbone, cat_as_text):\n",
        "    if mode == \"ft-transformer\":\n",
        "        hparams = {\"model.names\": [\"ft_transformer\",\n",
        "                                   \"hf_text\",\n",
        "                                   \"fusion_transformer\"],\n",
        "                   \"model.hf_text.checkpoint_name\": text_backbone,\n",
        "                   \"data.categorical.convert_to_text\": cat_as_text}\n",
        "    elif mode == \"mlp\":\n",
        "        hparams = {\"model.names\": [\"categorical_mlp\",\n",
        "                                   \"numerical_mlp\",\n",
        "                                   \"hf_text\",\n",
        "                                   \"fusion_mlp\"],\n",
        "                   \"model.hf_text.checkpoint_name\": text_backbone,\n",
        "                   \"data.categorical.convert_to_text\": cat_as_text}\n",
        "    else:\n",
        "        raise NotImplementedError(f\"mode={mode} is not supported!\")\n",
        "    return hparams\n",
        "\n",
        "\n",
        "def preprocess(df, with_tax_values=True, log_scale_lot=True,\n",
        "               log_scale_listed_price=True, has_label=True):\n",
        "    new_df = df.copy()\n",
        "    new_df.drop('Id', axis=1, inplace=True)\n",
        "    new_df['Elementary School'] = new_df['Elementary School'].apply(lambda ele: str(ele)[:-len(' Elementary School')] if str(ele).endswith('Elementary School') else ele)\n",
        "    if log_scale_lot:\n",
        "        new_df['Lot'] = np.log(new_df['Lot'] + 1)\n",
        "    if log_scale_listed_price:\n",
        "        log_listed_price = np.log(new_df['Listed Price']).clip(0, None)\n",
        "        new_df['Listed Price'] = log_listed_price\n",
        "    if with_tax_values:\n",
        "        new_df['Tax assessed value'] = np.log(new_df['Tax assessed value'] + 1)\n",
        "        new_df['Annual tax amount'] = np.log(new_df['Annual tax amount'] + 1)\n",
        "    else:\n",
        "        new_df.drop('Tax assessed value', axis=1, inplace=True)\n",
        "        new_df.drop('Annual tax amount', axis=1, inplace=True)\n",
        "    if has_label:\n",
        "        new_df['Sold Price'] = np.log(new_df['Sold Price'])\n",
        "    return new_df\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    import torch as th\n",
        "    th.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    if args.exp_path is None:\n",
        "        args.exp_path = f'automm_kaggle_house_{args.mode}_{args.automm_mode}_cat_to_text{args.cat_as_text}_{args.text_backbone}'\n",
        "\n",
        "    set_seed(args.seed)\n",
        "    train_df = pd.read_csv(os.path.join(args.data_path, 'train.csv'))\n",
        "    test_df = pd.read_csv(os.path.join(args.data_path, 'test.csv'))\n",
        "    # For the purpose of generating submission file\n",
        "    submission_df = pd.read_csv(os.path.join(args.data_path, 'sample_submission.csv'))\n",
        "    train_df = preprocess(train_df,\n",
        "                          with_tax_values=args.with_tax_values, has_label=True)\n",
        "    test_df = preprocess(test_df,\n",
        "                         with_tax_values=args.with_tax_values, has_label=False)\n",
        "    label_column = 'Sold Price'\n",
        "    eval_metric = 'r2'\n",
        "\n",
        "    automm_hyperparameters = get_automm_hyperparameters(args.automm_mode, args.text_backbone, args.cat_as_text)\n",
        "\n",
        "    tabular_hyperparameters = {\n",
        "        'GBM': [\n",
        "            {},\n",
        "            {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
        "        ],\n",
        "        'CAT': {},\n",
        "        'AG_AUTOMM': automm_hyperparameters,\n",
        "    }\n",
        "    if args.mode == 'single':\n",
        "        predictor = MultiModalPredictor(eval_metric=eval_metric, label=label_column, path=args.exp_path)\n",
        "        predictor.fit(train_df, time_limit=8*60, hyperparameters=automm_hyperparameters, seed=args.seed)\n",
        "    elif args.mode == 'weighted' or args.mode == 'stack5' or args.mode == 'single_bag5' or args.mode == 'single_bag4':\n",
        "        predictor = TabularPredictor(eval_metric=eval_metric, label=label_column, path=args.exp_path)\n",
        "\n",
        "        if args.mode == 'single_bag5':\n",
        "            tabular_hyperparameters = {\n",
        "                'AG_AUTOMM': automm_hyperparameters,\n",
        "            }\n",
        "            num_bag_folds, num_stack_levels = 5, 0\n",
        "        elif args.mode == 'weighted':\n",
        "            num_bag_folds, num_stack_levels = None, None\n",
        "        elif args.mode == 'stack5':\n",
        "            num_bag_folds, num_stack_levels = 5, 1\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        predictor.fit(train_df,\n",
        "                      time_limit=8*60,\n",
        "                      hyperparameters=tabular_hyperparameters,\n",
        "                      num_bag_folds=num_bag_folds,\n",
        "                      num_stack_levels=num_stack_levels)\n",
        "        leaderboard = predictor.leaderboard()\n",
        "        leaderboard.to_csv(os.path.join(args.exp_path, 'leaderboard.csv'))\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    predictions = np.exp(predictor.predict(test_df))\n",
        "    submission_df['Sold Price'] = predictions\n",
        "    submission_df.to_csv(os.path.join(args.exp_path, 'submission.csv'), index=None)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = get_parser()\n",
        "    args = parser.parse_args()\n",
        "    th.manual_seed(args.seed)\n",
        "    train(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSBXCtWo9V_F",
        "outputId": "983e6e75-b87d-4813-da18-02fb1f4c6a4c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kaggle_house.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single MultiModalPredictor (MLP)\n",
        "!rm -rf /content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator\n",
        "!python3 kaggle_house.py --automm-mode mlp --mode single 2>&1 | tee -a logs/automm_single_mlp.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nESQPAFq9f1A",
        "outputId": "f74a5df7-206a-4714-aa4a-c539523cc5f6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-14 17:45:01.904794: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-14 17:45:02.232154: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-14 17:45:02.332874: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-14 17:45:05.090699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Pytorch Version:    2.3.1+cu121\n",
            "CUDA Version:       12.1\n",
            "Memory Avail:       9.76 GB / 12.67 GB (77.0%)\n",
            "Disk Space Avail:   196.55 GB / 235.68 GB (83.4%)\n",
            "===================================================\n",
            "\n",
            "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
            "\n",
            "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
            "    ```shell\n",
            "    # Assume you have installed tensorboard\n",
            "    tensorboard --logdir /content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator\n",
            "    ```\n",
            "\n",
            "Seed set to 123\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "GPU Count: 1\n",
            "GPU Count to be Used: 1\n",
            "GPU 0 Name: Tesla T4\n",
            "GPU 0 Memory: 0.25GB/15.0GB (Used/Total)\n",
            "\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name              | Type                | Params | Mode \n",
            "------------------------------------------------------------------\n",
            "0 | model             | MultimodalFusionMLP | 13.9 M | train\n",
            "1 | validation_metric | R2Score             | 0      | train\n",
            "2 | loss_func         | MSELoss             | 0      | train\n",
            "------------------------------------------------------------------\n",
            "13.9 M    Trainable params\n",
            "0         Non-trainable params\n",
            "13.9 M    Total params\n",
            "55.514    Total estimated model params size (MB)\n",
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2800/5618 [05:10<05:12,  9.02it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   6%|â–‹         | 20/313 [00:00<00:12, 24.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  13%|â–ˆâ–Ž        | 40/313 [00:01<00:11, 23.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  19%|â–ˆâ–‰        | 60/313 [00:02<00:10, 24.31it/s]\u001b[A\n",
            "Validation DataLoader 0:  26%|â–ˆâ–ˆâ–Œ       | 80/313 [00:03<00:09, 24.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 100/313 [00:04<00:08, 24.56it/s]\u001b[A\n",
            "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/313 [00:04<00:07, 24.61it/s]\u001b[A\n",
            "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/313 [00:05<00:07, 24.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/313 [00:06<00:06, 24.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 180/313 [00:07<00:05, 24.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 200/313 [00:08<00:04, 24.36it/s]\u001b[A\n",
            "Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 220/313 [00:09<00:03, 24.33it/s]\u001b[A\n",
            "Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 240/313 [00:10<00:03, 23.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 260/313 [00:11<00:02, 23.26it/s]\u001b[A\n",
            "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 280/313 [00:12<00:01, 22.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 300/313 [00:13<00:00, 22.17it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:14<00:00, 21.77it/s]\u001b[A\n",
            "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2800/5618 [05:25<05:28,  8.59it/s]Epoch 0, global step 175: 'val_r2' reached 0.74078 (best 0.74078), saving model to '/content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator/epoch=0-step=175.ckpt' as top 3\n",
            "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4200/5618 [07:58<02:41,  8.78it/s]Time limit reached. Elapsed time is 0:08:00. Signaling Trainer to stop.\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   6%|â–‹         | 20/313 [00:00<00:12, 23.90it/s]\u001b[A\n",
            "Validation DataLoader 0:  13%|â–ˆâ–Ž        | 40/313 [00:01<00:11, 23.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  19%|â–ˆâ–‰        | 60/313 [00:02<00:10, 24.10it/s]\u001b[A\n",
            "Validation DataLoader 0:  26%|â–ˆâ–ˆâ–Œ       | 80/313 [00:03<00:09, 24.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 100/313 [00:04<00:08, 24.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/313 [00:04<00:07, 24.15it/s]\u001b[A\n",
            "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/313 [00:05<00:07, 24.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/313 [00:06<00:06, 24.18it/s]\u001b[A\n",
            "Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 180/313 [00:07<00:05, 24.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 200/313 [00:08<00:04, 24.22it/s]\u001b[A\n",
            "Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 220/313 [00:09<00:03, 24.31it/s]\u001b[A\n",
            "Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 240/313 [00:09<00:02, 24.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 260/313 [00:10<00:02, 23.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 280/313 [00:12<00:01, 23.19it/s]\u001b[A\n",
            "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 300/313 [00:13<00:00, 22.78it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:13<00:00, 22.53it/s]\u001b[A\n",
            "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4200/5618 [08:14<02:46,  8.50it/s]Epoch 0, global step 263: 'val_r2' reached 0.80767 (best 0.80767), saving model to '/content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator/epoch=0-step=263.ckpt' as top 3\n",
            "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4200/5618 [08:19<02:48,  8.41it/s]Start to fuse 2 checkpoints via the greedy soup algorithm.\n",
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:07<00:00, 10.53it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:09<00:00,  8.20it/s]AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
            "\n",
            "To load the model, use the code below:\n",
            "    ```python\n",
            "    from autogluon.multimodal import MultiModalPredictor\n",
            "    predictor = MultiModalPredictor.load(\"/content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator\")\n",
            "    ```\n",
            "\n",
            "If you are not satisfied with the model, try to increase the training time, \n",
            "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
            "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
            "\n",
            "\n",
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 989/989 [01:49<00:00,  9.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single MultiModalPredictor (FT-Transformer For Tabular)\n",
        "!python3 kaggle_house.py --automm-mode ft-transformer --mode single 2>&1 | tee -a logs/automm_single_ft.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMzEic1zAPFO",
        "outputId": "181bf164-2bbf-4284-a389-f023b9f1b1fe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-14 17:56:09.781867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-14 17:56:09.802891: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-14 17:56:09.809146: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-14 17:56:11.148422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Pytorch Version:    2.3.1+cu121\n",
            "CUDA Version:       12.1\n",
            "Memory Avail:       9.84 GB / 12.67 GB (77.6%)\n",
            "Disk Space Avail:   196.40 GB / 235.68 GB (83.3%)\n",
            "===================================================\n",
            "\n",
            "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
            "\n",
            "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
            "    ```shell\n",
            "    # Assume you have installed tensorboard\n",
            "    tensorboard --logdir /content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\n",
            "    ```\n",
            "\n",
            "Seed set to 123\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "GPU Count: 1\n",
            "GPU Count to be Used: 1\n",
            "GPU 0 Name: Tesla T4\n",
            "GPU 0 Memory: 0.25GB/15.0GB (Used/Total)\n",
            "\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name              | Type                        | Params | Mode \n",
            "--------------------------------------------------------------------------\n",
            "0 | model             | MultimodalFusionTransformer | 15.7 M | train\n",
            "1 | validation_metric | R2Score                     | 0      | train\n",
            "2 | loss_func         | MSELoss                     | 0      | train\n",
            "--------------------------------------------------------------------------\n",
            "15.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "15.7 M    Total params\n",
            "62.870    Total estimated model params size (MB)\n",
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2800/5618 [05:26<05:28,  8.59it/s]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   6%|â–‹         | 20/313 [00:01<00:19, 15.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  13%|â–ˆâ–Ž        | 40/313 [00:02<00:18, 14.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  19%|â–ˆâ–‰        | 60/313 [00:04<00:17, 14.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  26%|â–ˆâ–ˆâ–Œ       | 80/313 [00:04<00:14, 16.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 100/313 [00:05<00:12, 17.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/313 [00:06<00:10, 17.94it/s]\u001b[A\n",
            "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/313 [00:07<00:09, 18.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/313 [00:08<00:08, 19.00it/s]\u001b[A\n",
            "Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 180/313 [00:09<00:06, 19.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 200/313 [00:10<00:05, 19.71it/s]\u001b[A\n",
            "Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 220/313 [00:11<00:04, 19.99it/s]\u001b[A\n",
            "Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 240/313 [00:11<00:03, 20.25it/s]\u001b[A\n",
            "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 260/313 [00:12<00:02, 20.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 280/313 [00:13<00:01, 20.67it/s]\u001b[A\n",
            "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 300/313 [00:14<00:00, 20.74it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:15<00:00, 20.70it/s]\u001b[A\n",
            "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2800/5618 [05:42<05:44,  8.18it/s]Epoch 0, global step 175: 'val_r2' reached 0.86603 (best 0.86603), saving model to '/content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator/epoch=0-step=175.ckpt' as top 3\n",
            "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3980/5618 [07:58<03:17,  8.31it/s]Time limit reached. Elapsed time is 0:08:00. Signaling Trainer to stop.\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   6%|â–‹         | 20/313 [00:01<00:17, 16.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  13%|â–ˆâ–Ž        | 40/313 [00:02<00:16, 16.40it/s]\u001b[A\n",
            "Validation DataLoader 0:  19%|â–ˆâ–‰        | 60/313 [00:03<00:15, 15.85it/s]\u001b[A\n",
            "Validation DataLoader 0:  26%|â–ˆâ–ˆâ–Œ       | 80/313 [00:05<00:15, 15.37it/s]\u001b[A\n",
            "Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 100/313 [00:06<00:13, 15.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/313 [00:07<00:12, 15.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/313 [00:09<00:11, 14.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/313 [00:10<00:10, 14.86it/s]\u001b[A\n",
            "Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 180/313 [00:12<00:08, 14.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 200/313 [00:13<00:07, 15.32it/s]\u001b[A\n",
            "Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 220/313 [00:13<00:05, 15.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 240/313 [00:14<00:04, 16.26it/s]\u001b[A\n",
            "Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 260/313 [00:15<00:03, 16.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 280/313 [00:16<00:01, 17.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 300/313 [00:17<00:00, 17.39it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:17<00:00, 17.64it/s]\u001b[A\n",
            "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3980/5618 [08:17<03:24,  7.99it/s]Epoch 0, global step 249: 'val_r2' reached 0.90350 (best 0.90350), saving model to '/content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator/epoch=0-step=249.ckpt' as top 3\n",
            "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3980/5618 [08:23<03:27,  7.90it/s]Start to fuse 2 checkpoints via the greedy soup algorithm.\n",
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:08<00:00,  9.73it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:09<00:00,  8.52it/s]AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
            "\n",
            "To load the model, use the code below:\n",
            "    ```python\n",
            "    from autogluon.multimodal import MultiModalPredictor\n",
            "    predictor = MultiModalPredictor.load(\"/content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\")\n",
            "    ```\n",
            "\n",
            "If you are not satisfied with the model, try to increase the training time, \n",
            "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
            "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
            "\n",
            "\n",
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 989/989 [01:50<00:00,  8.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MultiModalPredictor + other Tree Models (Weighted Ensemble)\n",
        "!python3 kaggle_house.py --automm-mode ft-transformer --mode weighted 2>&1 | tee -a logs/automm_ft_weighted.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A4NruqhAPWd",
        "outputId": "83922eea-dd56-4061-8c9a-ad9f6da01356"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-14 18:07:05.775193: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-14 18:07:05.795275: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-14 18:07:05.801468: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-14 18:07:06.993100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.83 GB / 12.67 GB (77.6%)\n",
            "Disk Space Avail:   196.33 GB / 235.68 GB (83.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ... Time limit = 480s\n",
            "AutoGluon will save models to \"automm_kaggle_house_weighted_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\"\n",
            "Train Data Rows:    47439\n",
            "Train Data Columns: 39\n",
            "Label Column:       Sold Price\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (18.31532022829454, 11.517913006481267, 13.73905, 0.79676)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10157.81 MB\n",
            "\tTrain Data (Original)  Memory Usage: 101.06 MB (1.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tFitting RenameFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', 'Bedrooms', 'Middle School', 'High School', 'Flooring', 'Heating features', 'Cooling features', 'Appliances included', 'Laundry features', 'Parking features']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 10000 to 3951 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 17 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('int', [])                        :  1 | ['Zip']\n",
            "\t\t('object', [])                     :  5 | ['Type', 'Region', 'Elementary School', 'City', 'State']\n",
            "\t\t('object', ['datetime_as_object']) :  2 | ['Listed On', 'Last Sold On']\n",
            "\t\t('object', ['text'])               : 14 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :    4 | ['Type', 'Region', 'Elementary School', 'City']\n",
            "\t\t('category', ['text_as_category'])  :   14 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\t\t('float', [])                       :   17 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('int', [])                         :    1 | ['Zip']\n",
            "\t\t('int', ['binned', 'text_special']) :  169 | ['Address.char_count', 'Address.word_count', 'Address.capital_ratio', 'Address.lower_ratio', 'Address.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :    1 | ['State']\n",
            "\t\t('int', ['datetime_as_int'])        :   10 | ['Listed On', 'Listed On.year', 'Listed On.month', 'Listed On.day', 'Listed On.dayofweek', ...]\n",
            "\t\t('int', ['text_ngram'])             : 3675 | ['__nlp__.000', '__nlp__.000 in', '__nlp__.000 in december', '__nlp__.000 in november', '__nlp__.000 in october', ...]\n",
            "\t\t('object', ['text'])                :   14 | ['Address_raw_text', 'Summary_raw_text', 'Heating_raw_text', 'Cooling_raw_text', 'Parking_raw_text', ...]\n",
            "\t129.6s = Fit runtime\n",
            "\t39 features in original data used to generate 3905 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 431.31 MB (4.3% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 132.85s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.05269925588650688, Train Rows: 44939, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}],\n",
            "\t'CAT': {},\n",
            "\t'AG_AUTOMM': {'model.names': ['ft_transformer', 'hf_text', 'fusion_transformer'], 'model.hf_text.checkpoint_name': 'google/electra-small-discriminator', 'data.categorical.convert_to_text': False},\n",
            "}\n",
            "Fitting 4 L1 models ...\n",
            "Fitting model: LightGBM ... Training model for up to 347.15s of the 347.05s of remaining time.\n",
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "\t0.9555\t = Validation score   (r2)\n",
            "\t36.43s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ... Training model for up to 310.37s of the 310.28s of remaining time.\n",
            "\t0.9589\t = Validation score   (r2)\n",
            "\t211.59s\t = Training   runtime\n",
            "\t1.38s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 96.88s of the 96.79s of remaining time.\n",
            "\tRan out of time, early stopping on iteration 76.\n",
            "\t0.945\t = Validation score   (r2)\n",
            "\t96.92s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 347.15s of the -0.72s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT': 0.667, 'LightGBM': 0.333}\n",
            "\t0.9599\t = Validation score   (r2)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 484.68s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1551.0 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"automm_kaggle_house_weighted_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\")\n",
            "[1000]\tvalid_set's l2: 0.0277164\tvalid_set's r2: 0.95751\n",
            "[2000]\tvalid_set's l2: 0.027177\tvalid_set's r2: 0.958337\n",
            "[3000]\tvalid_set's l2: 0.0269695\tvalid_set's r2: 0.958655\n",
            "[4000]\tvalid_set's l2: 0.0268747\tvalid_set's r2: 0.958801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MultiModalPredictor + other Tree Models (5-fold Stack Ensemble)\n",
        "!python3 kaggle_house.py --automm-mode ft-transformer --mode stack5 2>&1 | tee -a logs/automm_ft_stack5.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbyrObEGAPeq",
        "outputId": "c8c12837-5148-414f-f96a-49dedfa7358a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-14 18:16:13.510380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-14 18:16:13.531139: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-14 18:16:13.537799: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-14 18:16:14.723407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.85 GB / 12.67 GB (77.7%)\n",
            "Disk Space Avail:   195.93 GB / 235.68 GB (83.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ... Time limit = 480s\n",
            "AutoGluon will save models to \"automm_kaggle_house_stack5_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\"\n",
            "Train Data Rows:    47439\n",
            "Train Data Columns: 39\n",
            "Label Column:       Sold Price\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (18.31532022829454, 11.517913006481267, 13.73905, 0.79676)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10178.26 MB\n",
            "\tTrain Data (Original)  Memory Usage: 101.06 MB (1.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tFitting RenameFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', 'Bedrooms', 'Middle School', 'High School', 'Flooring', 'Heating features', 'Cooling features', 'Appliances included', 'Laundry features', 'Parking features']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 10000 to 3938 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 17 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('int', [])                        :  1 | ['Zip']\n",
            "\t\t('object', [])                     :  5 | ['Type', 'Region', 'Elementary School', 'City', 'State']\n",
            "\t\t('object', ['datetime_as_object']) :  2 | ['Listed On', 'Last Sold On']\n",
            "\t\t('object', ['text'])               : 14 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :    4 | ['Type', 'Region', 'Elementary School', 'City']\n",
            "\t\t('category', ['text_as_category'])  :   14 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n",
            "\t\t('float', [])                       :   17 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n",
            "\t\t('int', [])                         :    1 | ['Zip']\n",
            "\t\t('int', ['binned', 'text_special']) :  169 | ['Address.char_count', 'Address.word_count', 'Address.capital_ratio', 'Address.lower_ratio', 'Address.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :    1 | ['State']\n",
            "\t\t('int', ['datetime_as_int'])        :   10 | ['Listed On', 'Listed On.year', 'Listed On.month', 'Listed On.day', 'Listed On.dayofweek', ...]\n",
            "\t\t('int', ['text_ngram'])             : 3662 | ['__nlp__.000', '__nlp__.000 in', '__nlp__.000 in december', '__nlp__.000 in november', '__nlp__.000 in october', ...]\n",
            "\t\t('object', ['text'])                :   14 | ['Address_raw_text', 'Summary_raw_text', 'Heating_raw_text', 'Cooling_raw_text', 'Parking_raw_text', ...]\n",
            "\t129.6s = Fit runtime\n",
            "\t39 features in original data used to generate 3892 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 430.14 MB (4.3% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 132.56s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}],\n",
            "\t'CAT': {},\n",
            "\t'AG_AUTOMM': {'model.names': ['ft_transformer', 'hf_text', 'fusion_transformer'], 'model.hf_text.checkpoint_name': 'google/electra-small-discriminator', 'data.categorical.convert_to_text': False},\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 4 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 231.57s of the 347.36s of remaining time.\n",
            "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 35.77% memory usage per fold, 71.55%/80.00% total).\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=35.77%)\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "\t0.9412\t = Validation score   (r2)\n",
            "\t196.12s\t = Training   runtime\n",
            "\t9.95s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 17.54s of the 133.33s of remaining time.\n",
            "\tMemory not enough to fit 5 folds in parallel. Will train 2 folds in parallel instead (Estimated 38.67% memory usage per fold, 77.35%/80.00% total).\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=38.67%)\n",
            "\t0.0771\t = Validation score   (r2)\n",
            "\t123.39s\t = Training   runtime\n",
            "\t6.4s\t = Validation runtime\n",
            "Completed 1/5 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 347.44s of the 0.24s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.9412\t = Validation score   (r2)\n",
            "\t0.09s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 3 L2 models ...\n",
            "Completed 1/5 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 347.44s of the -1.51s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.9412\t = Validation score   (r2)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 485.34s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 953.9 rows/s (9488 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"automm_kaggle_house_stack5_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\")\n",
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/automm_kaggle_house*/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQtos8WrOhdS",
        "outputId": "3da7944c-4bff-4b74-b259-5166f2a335f9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator:\n",
            "assets.json\t     df_preprocessor.pkl\t\t\t\t hparams.yaml\n",
            "config.yaml\t     events.out.tfevents.1726336577.6f9fb638bc1d.4818.0  model.ckpt\n",
            "data_processors.pkl  hf_text\t\t\t\t\t\t submission.csv\n",
            "\n",
            "/content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator:\n",
            "assets.json\t     df_preprocessor.pkl\t\t\t\t hparams.yaml\n",
            "config.yaml\t     events.out.tfevents.1726335925.6f9fb638bc1d.1947.0  model.ckpt\n",
            "data_processors.pkl  hf_text\t\t\t\t\t\t submission.csv\n",
            "\n",
            "/content/automm_kaggle_house_stack5_ft-transformer_cat_to_textFalse_google/electra-small-discriminator:\n",
            "leaderboard.csv  metadata.json\tpredictor.pkl\tutils\n",
            "learner.pkl\t models\t\tsubmission.csv\tversion.txt\n",
            "\n",
            "/content/automm_kaggle_house_weighted_ft-transformer_cat_to_textFalse_google/electra-small-discriminator:\n",
            "leaderboard.csv  metadata.json\tpredictor.pkl\tutils\n",
            "learner.pkl\t models\t\tsubmission.csv\tversion.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "from autogluon.multimodal import MultiModalPredictor\n",
        "\n",
        "loaded_predictor = MultiModalPredictor.load(\"/content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\")\n",
        "print(loaded_predictor.fit_summary())\n",
        "\n",
        "loaded_predictor = MultiModalPredictor.load(\"/content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator\")\n",
        "print(loaded_predictor.fit_summary())\n",
        "\n",
        "loaded_predictor = TabularPredictor.load(\"/content/automm_kaggle_house_stack5_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\")\n",
        "print(loaded_predictor.leaderboard())\n",
        "\n",
        "loaded_predictor = TabularPredictor.load(\"/content/automm_kaggle_house_weighted_ft-transformer_cat_to_textFalse_google/electra-small-discriminator\")\n",
        "print(loaded_predictor.leaderboard())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN-RsgANXVh9",
        "outputId": "013f4ac5-4829-4c89-eea9-60eb2b58d6a8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Load pretrained checkpoint: /content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'val_r2': None, 'training_time': None}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Load pretrained checkpoint: /content/automm_kaggle_house_single_mlp_cat_to_textFalse_google/electra-small-discriminator/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'val_r2': None, 'training_time': None}\n",
            "                 model  score_val eval_metric  pred_time_val    fit_time  \\\n",
            "0      LightGBM_BAG_L1   0.941223          r2       9.946417  196.122740   \n",
            "1  WeightedEnsemble_L3   0.941223          r2       9.947645  196.186393   \n",
            "2  WeightedEnsemble_L2   0.941223          r2       9.948374  196.216867   \n",
            "3    LightGBMXT_BAG_L1   0.077052          r2       6.396061  123.393576   \n",
            "\n",
            "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
            "0                9.946417         196.122740            1       True   \n",
            "1                0.001228           0.063653            3       True   \n",
            "2                0.001957           0.094127            2       True   \n",
            "3                6.396061         123.393576            1       True   \n",
            "\n",
            "   fit_order  \n",
            "0          1  \n",
            "1          4  \n",
            "2          3  \n",
            "3          2  \n",
            "                 model  score_val eval_metric  pred_time_val    fit_time  \\\n",
            "0  WeightedEnsemble_L2   0.959899          r2       1.611901  248.059139   \n",
            "1           LightGBMXT   0.958855          r2       1.377954  211.588674   \n",
            "2             LightGBM   0.955545          r2       0.233168   36.429240   \n",
            "3             CatBoost   0.944956          r2       0.206290   96.917800   \n",
            "\n",
            "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
            "0                0.000779           0.041225            2       True   \n",
            "1                1.377954         211.588674            1       True   \n",
            "2                0.233168          36.429240            1       True   \n",
            "3                0.206290          96.917800            1       True   \n",
            "\n",
            "   fit_order  \n",
            "0          4  \n",
            "1          2  \n",
            "2          1  \n",
            "3          3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!KAGGLE_CONFIG_DIR=$(pwd) kaggle competitions submit -c california-house-prices -f /content/automm_kaggle_house_single_ft-transformer_cat_to_textFalse_google/electra-small-discriminator/submission.csv -m \"my first submission\""
      ],
      "metadata": {
        "id": "dboDFi0WZWNJ"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}